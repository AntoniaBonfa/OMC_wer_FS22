---
title: "Mini Challenge wer: Vorhersage Abstimmungen Mai"
output: html_notebook
---


Als erstes laden wir alle Pakete, die für dieses Projekt benötigt werden:
```{r Bibliotheken importieren}
library(tidymodels) #Entscheidungsbaum
library(tidyverse) #Datawrangling, Visualisierungen
library(plotly) # Interaktive Visualisierungen
library(formattable) #für Formatierungen -> hier um Prozente schön darzustellen
library(rpart) #Entscheidungsbaum
library(rpart.plot) #Entscheidungsbaum
library(rcompanion)#CramerV

```

Danach wird der Datensatz eingelesen: Swissvotes Datensatz sowie unser eigener Datensatz mit den Vorhersagen der Tamedia & SRG
```{r Datensätze einlesen}

df <- read.csv("https://swissvotes.ch/page/dataset/swissvotes_dataset.csv", header=TRUE, sep=";", na = c("NA", "."))
df_vorhersagen <- read.csv("C:/Users/Antonia/Documents/GitHub/OMC_wer_FS22/Vorhersagen_SRG_Tamedia.csv", header=TRUE, sep=",", na = c("NA", "."))

  
```
Unsere Fragestellung lautet: Wie wahrscheinlich ist es, dass die drei Initiativen vom 15. Mai 2022 angenommen werden. 
Im nächsten Schritt werden die Daten bereinigt, so dass wir einen Datensatz erhalten, mit dem wir arbeiten können. 
```{r Data Wrangling}

#Variablen definieren um nachher mehrere Spalten gleichzeitig zu mutieren
parteien <- c(".svp", ".fdp", ".sps", ".cvp", ".gps", ".mitte")


hauptthema <- df %>%
  select(d1e1, d2e1 ,d3e1)


positionen  <- df %>%
  select(ends_with(".pos")|starts_with("p.")|starts_with("pdev")) 

daten <- df %>%
  select(datum, starts_with("dat."))

resultate <- df %>%
  select(ends_with("annahme")| volk | stand)

Thema <- df %>%
  select(d1e3, d2e3, d3e3)


#bereinigten Datensatz erstellen (Variablen benennen, Spalten umbenennen, gewisse NAs droppen, fehlende Werte ergänzen)
df_clean <- df %>%
  mutate(p.cvp = ifelse(p.cvp == "9999", p.mitte, p.cvp))%>% #CVP wurde zu Mitte -> fehlende Daten cvp durch Daten der Mitte ergänzt
  mutate(w.cvp = sum(w.cvp, w.mitte))%>%  #CVP wurde zu Mitte -> fehlende Daten cvp durch Daten der Mitte ergänzt
  mutate(rechtsform = factor(case_when(
    rechtsform == 1 ~ "Obligatorisches Referendum", #OR
    rechtsform == 2 ~ "Fakultatives Referendum", #FR
    rechtsform == 3 ~ "Volksinitiative", #VI
    rechtsform == 4 ~ "Gegenentwurf zu Volksinitiative", #GV
    rechtsform == 5 ~ "Stichfrage")))%>%  #S
  mutate(across(names(positionen), 
           ~ factor(case_when(. == 1 ~ "Befürwortend",
    .== 2 ~"Ablehnend",
    .== 3 ~"Keine",
    .== 4 ~"Leere Abgabe",
    .== 5 ~"Stimmfreigabe",
    .== 8 ~"Vorzug für den Gegenentwurf",
    .== 9 ~"Vorzug für Volksinitiative",
    . == 66 ~"keine",
    . == 9999 ~"Partei ex. nicht",)))) %>%
  mutate(across(names(resultate), 
                ~ factor(case_when(. == 0 ~"abgelehnt", 
                .== 1 ~ "angenommen", 
                .== 3 ~ "Ständemehr nicht nötig", 
                .== 8 ~ "Gegenentwurf angenommen", 
                .== 9 ~ "Volksinitiative angenommen" )))) %>% 
  drop_na(annahme) %>% 
  mutate(volkja.proz = as.numeric(volkja.proz)) %>% 
  select(datum, titel_kurz_d, anzahl, rechtsform, d1e1:br.pos, bv.pos:srnein, unter.quorum, unter_g, unter_u, ends_with(parteien), ja.lager:neutral.summe, volk:ktjaproz) %>%
  mutate(datum = as.Date(datum, "%d.%m.%Y")) %>% 
  rename(p.cvp_mitte = p.cvp, w.cvp_mitte = w.cvp)  %>% 
  select(-c(p.mitte, w.mitte))

pos_parteien <- names(select(df_clean, starts_with("p.")))
```


```{r Datensätze für die Abstimmungen im Mai}

#Abstimmungen vom Mai herausfiltern
Abstimmungen_Mai <- df_clean %>%
  filter(datum > as.Date("01.05.2022", "%d.%m.%Y" )) 

```

Für unser Wahrscheinlichkeitsmodell haben wir folgende Kriterien definiert, die wir untersuchen wollen: 
Rechtsform (Volksinitiative, fakultatives und obligatorisches Referendum, Gegenvorschlag zur Volksinitiative). Dazu kommt die Haltung des Bundesrats (befürwortend, ablehnend)sowie die Resultate ähnlicher Abstimmungen. Ebenfalls angeschaut wird die Haltung der grössten Parteien (SVP, SP, FDP, Gründe/Mitte, CVP), wobei wir uns auf befürwortend und  ablehnend beschränkt haben. Ausserdem schauen wir uns die letzten Umfragewellen der Tamedia und der SRG an und bestimmen, wie korrekt sie mit ihren Vorhersagen sind. 

Weitere Kriterien, bei denen wir denken dass sie einen Einfluss auf das Resultat haben, die wir aber nicht berücksichtigt haben, sind beispielsweise der Urheber einer Abstimmung und die Medienresonanz. Wir haben sie nicht berücksichtigt, weil die Medienresonanz oft im Nachhinein bestimmt wird und wir schlicht und einfach nicht alles anschauen können. 

Für alle drei Abstimmungen, die wir uns genauer anschauen, gilt:
- Rechtsform = Fakultatives Referendum
- Haltung des Bundesrats = Befürwortend
- Vorhersage SRG = Annahme
- Vorhersage Tamedia = Annahme

Diese Wahrscheinlichkeiten sind also identisch für alle Vorlagen:


```{r Wahrscheinlichkeitsmodell: allgemeine Wahrscheinlichkeiten}

total_vorlagen <- unlist(df_clean %>% count()) 
n_angenommen <-unlist(df_clean %>% filter(annahme == "angenommen") %>% count()) 
n_abgelehnt <- total_vorlagen - n_angenommen
(prob_annahme <- n_angenommen / total_vorlagen)

#Wahrscheinlichkeiten für die Positionen der Parteien (P(C) ∩ P(D) ∩ P(E) ∩ P(F) ∩ P(A)), wenn es sich um ein Fak. Ref handelt:
df_clean %>% 
  #filter(rechtsform == "Fakultatives Referendum")%>% 
  filter_at(vars(pos_parteien), all_vars(.=="Befürwortend"|.== "Ablehnend")) %>% 
  select(pos_parteien, annahme, ) %>%
  count(p.svp, p.fdp, p.sps, p.cvp_mitte, p.gps, annahme) %>% 
  mutate(prob = percent(n/sum(n))) %>% 
  arrange(desc(prob))


#Wahrscheinlichkeiten dass BR ja empfiehlt, wenn Rechtsform Fakultatives Referendum ist (P(B2)):
df_clean %>% 
  filter(rechtsform =="Fakultatives Referendum") %>% 
  select(rechtsform, br.pos) %>% 
  count(rechtsform, br.pos) %>%
  mutate(prob = percent(n/sum(n)))
  
#wahrscheinlichkeit, dass eine Abstimmung angenommen wird bei befürwortender Haltung des BR (P(A2) ∩ P(B2))
brpos <- df_clean %>% 
  filter(br.pos == "Befürwortend") %>% 
  select(br.pos, annahme) %>% 
  count(br.pos, annahme) %>% 
  mutate(prob = percent(n/sum(n)))
(prob_brpos <- brpos[2,4])

#Wahrscheinlichkeit, dass ein fakultatives Referendum angenommen wird
FR <- df_clean %>% 
  filter(rechtsform == "Fakultatives Referendum") %>% 
  select(rechtsform, annahme) %>% 
  count(rechtsform, annahme) %>% 
  mutate(prob = percent(n/sum(n)))
(prob_FR <- FR[2,4])

#Wahrscheinlichkeiten, dass eine Abstimmung angenommen wird, wenn die Rechtsform Fakultatives Referendum ist & der BR befürwortet
FR_BR <- df_clean %>% 
  filter(br.pos == "Befürwortend", rechtsform == "Fakultatives Referendum") %>% 
  select(br.pos, annahme) %>% 
  count(br.pos, annahme) %>% 
  mutate(prob = percent(n/sum(n)))
(prob_FR_BR <- FR_BR[2,4])

#Wahrscheinlichkeit, dass Vorhersage der Tamedia korrekt ist:

Tamedia_ja <- df_vorhersagen %>%
  filter(Tamedia == "Annahme") %>% 
  count(Resultat) %>% 
  mutate(prob = percent(n/sum(n)))

Tamedia_nein <- df_vorhersagen %>%
  filter(Tamedia == "Ablehnung") %>% 
  count(Resultat) %>% 
  mutate(prob = percent(n/sum(n)))

(prob_Tamedia <- Tamedia_ja[2,3]*Tamedia_nein[1,3])

#Wahrscheinlichkeit, dass Vorhersage der SRG korrekt ist:

SRG_ja <- df_vorhersagen %>%
  filter(SRG == "Annahme") %>% 
  count(Resultat) %>% 
  mutate(prob = percent(n/sum(n)))

SRG_nein <- df_vorhersagen %>%
  filter(SRG == "Ablehnung") %>% 
  count(Resultat) %>% 
  mutate(prob = percent(n/sum(n)))

(prob_SRG <- SRG_ja[2,3]*SRG_nein[1,3])
```

Zusätzlich hat jede Vorlage unterschiedliche Wahrscheinlichkeiten für die Themen der Parteien: 
```{r Wahrscheinlichkeit nach Themen}
#Themen vom Mai anschauen
select(Abstimmungen_Mai,titel_kurz_d,d1e3,d2e3,d3e3)

#Vektoren mit den Themen pro Vorlage
filmgesetz_thema <- c(12.53, 4.13)
organspende_thema <- c(10.11,1.62)
frontex_thema <- c(2.22, 10.32)

aehnlich_filmgesetz <- filter(df_clean, d1e3 %in% filmgesetz_thema | d2e3 %in% filmgesetz_thema |d3e3 %in% filmgesetz_thema)
aehnlich_organspende <- filter(df_clean, d1e3 %in% organspende_thema | d2e3 %in% organspende_thema |d3e3 %in% organspende_thema)
aehnlich_frontex <- filter(df_clean, d1e3 %in% frontex_thema | d2e3 %in% frontex_thema |d3e3 %in% frontex_thema)

#Funktion um Wahrscheinlichkeit zu berechnen
prob_Vorlagen <- function(Vorlagenfilter){
  prob_thema <- Vorlagenfilter %>% 
  count(annahme) %>% 
  mutate(prob = percent(n/sum(n)) )
  return (prob_thema[2,3])
}

#Berechnung Wahrscheinlichkeiten:
(prob_Filmgesetz_Thema <- prob_Vorlagen(aehnlich_filmgesetz))
(prob_Organspende_Thema <-prob_Vorlagen(aehnlich_organspende))
(prob_Frontex_Thema <-prob_Vorlagen(aehnlich_frontex))
```

Und für jede Initiative gibt es die Haltung der Parteien. 
```{r Wahrscheinlichkeiten nach Parteiparolen}

#Tabelle mit Parteipositionen zur Kontrolle:
Abstimmungen_Mai %>% 
  select(titel_kurz_d, starts_with("p."))

parteien_filmgesetz <-  filter(df_clean, p.svp == "Ablehnend" & p.fdp == "Ablehnend" & p.sps == "Befürwortend" & p.cvp_mitte == "Befürwortend" & p.gps == "Befürwortend" )

parteien_organspende  <-  filter(df_clean, p.svp == "Ablehnend" & p.fdp == "Befürwortend" & p.sps == "Befürwortend" & p.cvp_mitte == "Befürwortend" & p.gps == "Befürwortend")

parteien_frontex <- filter(df_clean, p.svp == "Befürwortend" & p.fdp == "Befürwortend" & p.sps == "Ablehnend" & p.cvp_mitte == "Befürwortend" & p.gps == "Ablehnend")

#einzelne Wahrscheinlichkeiten berechnen
(prob_Filmgesetz_parteien <- prob_Vorlagen(parteien_filmgesetz))
(prob_Organspende_parteien <- prob_Vorlagen(parteien_organspende))
(prob_Frontex_parteien <- prob_Vorlagen(parteien_frontex))

```
Mit all diesen Wahrscheinlichkeiten nach Kriterien können wir nun unser Modell für jede Vorlage erstellen.
Die Wahrscheinlichkeit, dass eine Vorlage angenommen wird, ergibt sich aus dem Mittelwert aller Wahrscheinlichkeiten:
Für Tamedia & SRG wurden die Vorhersagewerte gemäss letzter Umfragewelle genommen, da die Wahrscheinlichkeit, dass die Vorhersage korrekt ist mit 93,3% (für die Umfragen die wir geprüft haben) recht hoch ist. 
```{r Wahrscheinlichkeitsmodell für jede Vorlage}

Kriterien <- c("Wahrscheinlichkeit nach Rechtsform", 
               "Wahrscheinlichkeit nach Tamedia", 
               "Wahrscheinlichkeit nach SRG", 
               "Wahrscheinlichkeit nach Parteiposition", 
               "Wahrscheinlichkeit nach Thema", 
               "Wahrscheinlichkeit nach Empfehlung Bundesrat")



(Filmgesetz_Modell <- data.frame(Kriterien, P = c(prob_FR_BR, 
                                 prob_Tamedia = 0.52,
                                 prob_SRG = 0.59,
                                 prob_Filmgesetz_parteien,
                                 prob_Filmgesetz_Thema,
                                 prob_brpos)))



(Organspende_Modell <- data.frame(Kriterien, P = c(prob_FR_BR, 
                                 prob_Tamedia = 0.56,
                                 prob_SRG = 0.63,
                                 prob_Organspende_parteien,
                                 prob_Organspende_Thema,
                                 prob_brpos)))


(Frontex_Modell <- data.frame(Kriterien, P = c(prob_FR_BR, 
                                 prob_Tamedia = 0.56,
                                 prob_SRG = 0.63,
                                 prob_Frontex_parteien,
                                 prob_Frontex_Thema,
                                 prob_brpos)))



prob_Filmgesetz <- mean(unlist(Filmgesetz_Modell["P"]))
prob_Organspende <- mean(unlist(Organspende_Modell["P"]))
prob_Frontex <- mean(unlist(Frontex_Modell["P"]))

paste("Wahrscheinlichkeit, dass Filmgesetz angenommen wird:", percent(prob_Filmgesetz))
paste("Wahrscheinlichkeit, dass Transplantationsgesetz angenommen wird:", percent(prob_Organspende))
paste("Wahrscheinlichkeit, dass Frontex angenommen wird:", percent(prob_Frontex))

```

Anhand unserer Berechnungen wissen wir, wie die Wahrscheinlichkeiten für gewisse Ereignisse sind. Diese müssen wir jetzt mittels Hypothesentest prüfen.Um zu prüfen, ob wir aus unseren beobachteten Werten schliessen dürfen, dass eine Vorlage angenommen wird, führen wir einen Hypothesentest für jedes Modell durch. Da unsere Alternativhypothese lautet, dass die Wahrscheinlichkeiten unserer Vorlagen grösser ist, als die durchschnittliche Wahrscheinlichkeit einer Annahme, wenden wir einen rechtsseitigen Test an. Als Signifikationsniveau Alpha wählen wir 5 Prozent. 
Zuerst ermitteln wir die Standartabweichung der Basiswahrscheinlichkeit, also die Annahme einer Vorlage, und die Standartabweichung, also die Ablehnung einer Vorlage. Von diesen beiden ziehen wir dann die Quadratwurzel, um die Standartabweichung allgemein zu erhalten. 
Danach berechnen wir den P-Wert, indem wir zuerst den Z-Wert für jede Vorlage berechnen und diesen in die P-Norm-Funktion eingeben. 
```{r Verteilung der Daten prüfen}

#Histogram zur Prüfung, wie die Daten verteilt sind
ggplot(df_clean, aes(volkja.proz)) +
  geom_histogram(bins = 25)+
  labs(title = "Verteilung Prozentualer ja-Stimmen Anteil",
       x = "Prozentsatz Ja-Stimmen",
       y = "Anzahl Abstimmungen") 

# -> die Daten scheinen in etwa Normalverteilt zu sein. 

#Visualisierung Q-Q Plot -> die Daten sind nicht exakt Normalverteilt (Die Enden sind dazu zu dünn)
qqnorm(df_clean$volkja.proz)
qqline(df_clean$volkja.proz,col="green")

#Überprüfung mittels bootstrapping : wir nehmen 5000 Stichproben von unserem Datensatz und berechnen jeweils den Mittelwert der Stichprobe. 
set.seed(123)
bootstraping <- (replicate(n=5000, 
                       expr = {
                         df_clean %>% 
                           slice_sample(prop = 1, replace = TRUE) %>% 
                           summarize(mean_japroz = mean(volkja.proz)) %>% 
                           pull(mean_japroz)
                        }))


#Verteilung visualisieren -> die Stichproben sind Normalverteilt = Zentraler Grenzwertsatz!
tibble(resample_mean = bootstraping) %>% 
  ggplot(aes(resample_mean)) +
  geom_histogram() +
  labs(title = "Verteilung nach Boostrapping",
       x = "Durchschnitt Ja-Prozentsatz pro Stichprobe",
       y = "Anzahl Stichproben") 

```
Unsere Nullhypothese lautet: die Wahrscheinlichkeit, dass eine Vorlage angenommen wird, ist gleich wie bei den vergangenen Abstimmungen.
Alternative: die Wahrscheinlichkeit ist höher als dieser Durchschnitt. 
```{r Hypothesentests der einzelnen Vorlagen}

#Statistische Kennzahlen von einzelnen Variablen ermitteln (Standardabweichung, Mittelwert)
volk_sd <- sd(df_clean$volkja.proz)
volk_mean <- mean(df_clean$volkja.proz)

#Standardabweichung von der Basiswahrscheinlichkeit
(se_annahme <- (prob_annahme*(1-prob_annahme)**2)/(n_angenommen))
(se_ablehnung <- (prob_annahme*(1-prob_annahme)**2)/(n_abgelehnt))

se_total <- sqrt(se_annahme + se_ablehnung)


#Signifikanzniveau festlegen. Da es keine kritischen Daten sind ist 0.5 für alle Hypothesen ausreichend
alpha = 0.05


#Funktion um P-Wert zu berechnen
p_wert <- function(P_Vorlage) {
  resultat <- pnorm((P_Vorlage-prob_annahme)/se_total, lower.tail = FALSE) #rechtsseitiger Test
  return(ifelse(resultat < alpha, paste("P-Wert:",resultat,"ist kleiner als Signifikanzniveau: Nullhypothese muss verworfen werden."),paste("P-Wert:",resultat,"ist grösser als Signifikanzniveau: Nullhypothese ist erwiesen.") ))
}

p_wert(prob_Filmgesetz)
p_wert(prob_Organspende)
p_wert(prob_Frontex)

```
Zusätzlich zum Hypothesentest für die einzelnen Vorlagen haben wir noch den Einfluss einzelner Variablen mittels Hypothesentest überprüft.
```{r Funktionen definieren für CramerV und Fisher-Test}

hypo_fisher <- function(data){
  fisher <- fisher.test(data)
  return (ifelse(fisher$p.value < alpha, paste("P-Wert (", fisher, ") kleiner als Signifikanzniveau: H0 muss verworfen werden."), 
                 paste("P-Wert (", fisher, ") grösser als Signifikanzniveau: H0 ist korrekt.") ))
}

hypo_cramer <- function(data){
cramer <- cramerV(data)
return (case_when(cramer<0.4 ~ paste("CramerV Wert:",cramer, "- keine Abhängigkeit"), 
          cramer<0.7 ~ paste("CramerV Wert:",cramer, "- Mittlere Abhängigkeit"),
          cramer>0.7 ~ paste("CramerV Wert:",cramer, "- Hohe Abhängigkeit")))
}

```

Hypothese 1: Aus der Vorhersage der Tamedia kann nicht auf das Resultat geschlossen werden (H0) / kann das Resultat vorhergesagt werden (Ha)
```{r Hypothese 1: Vorhersage Tamedia} 

#Kreuztabelle Verteilung
(H1 <- table(df_vorhersagen$Tamedia, df_vorhersagen$Resultat))

#Fishers Test durchführen
hypo_fisher(H1)

```
Hypothese 2: Aus der Vorhersage der SRG kann nicht auf das Resultat geschlossen werden (H0) / kann das Resultat vorhergesagt werden (Ha)}
```{r Hypothese 2: Vorhersage SRG} 

#Kreuztabelle Verteilung
(H2 <- table(df_vorhersagen$SRG, df_vorhersagen$Resultat))

#Fishers Test durchführen
hypo_fisher(H2)
```

Hypothese 3: Es gibt keinen signifikanten Zusammenhang zwischen der Empfehlung des Bundesrates und dem Ergebniss (H0) / es gibt einen signifikanten Zusammenhang (Ha)
```{r Hypothese 3: Empfehlung Bundesrat}

#für CramerV darf der Datensatz keine NAs enthalten -> bereinigten Datensatz erstellen: 
df_cramer_3 <- df_clean %>% 
  drop_na(br.pos, volk) %>% 
  mutate(volk = droplevels(volk), br.pos = droplevels(br.pos))

#Kreuztabelle der Verteilungen
(H3 <- table(df_cramer_3$br.pos, df_cramer_3$volk))

#Hypothese überprüfen mittels CramerV & Fishers exact Test (fisher Test zur Sicherheit, da unser Datensatz nicht sehr gross ist)

hypo_fisher(H3)
hypo_cramer(H3)
```



Hypothese 4: die Rechtsform hat keinen Einfluss auf das Abstimmungsresultat (H0) / hat einen Einfluss (Ha)
```{r Hypothese 4: Rechtsform}

#für CramerV darf der Datensatz keine NAs enthalten -> bereinigten Datensatz erstellen: 
df_cramer_4 <- df_clean %>% 
  drop_na(rechtsform, annahme) %>% 
  mutate(annahme = droplevels(annahme), rechtsform = droplevels(rechtsform))

#Kreuztabelle der Verteilungen
(H4 <- table(df_cramer_4$rechtsform, df_cramer_4$annahme))

#Hypothese überprüfen mittels CramerV & Fishers exact Test (fisher Test zur Sicherheit, da unser Datensatz nicht sehr gross ist)
hypo_fisher(H4)
hypo_cramer(H4)


```
Die Resultate für alle drei Vorlagen sind kleiner als unser Signifikanzniveau, weswegen wir die Nullhypothese für alle drei Vorlagen verwerfen können. 
Zusätzlich haben wir noch einen Hypothesentest für einzelne Kriterien durchgeführt. Da diese Daten alle kategorisch sind, haben wir jeweils einen CramerV-Test und einen Fishers exact Test for counted data durchgeführt. Dafür haben wir jeweils Kreuztabellen gebildet mit den Kriterien und der Zielvariable. 
Bei allen getesteten Kriterien war das Resultat aus dem Fisher Test deutlich geringer als unser Signifikanzniveau, weswegen wir für alle die Nullhypothese verwerfen können. Denn der CramerV Wert kann jeweils einen Wert von 0 bis 1 annehmen, wobei wie bei der Korrelation gilt, je näher der Wert zu 1, desto höher die Abhängigkeit. Bei den getesteten Kriterien war der Wert jeweils um 0.5, was einer mittleren Abhängigkeit entspricht. 


Als zusätzlichen Schritt haben wir versucht, einen Entscheidungsbaum zu erstellen, der das Resultat ebenfalls vorhersagt. 
```{r Entscheidungsbaum Set-up} 

#reduzierter Datensatz für Baum (Entfernung Resultatvariablen wie Volk, Kanton, Resultate pro Kanton etc):
data_baum <- df_clean %>% select(rechtsform, names(hauptthema), br.pos:nr.pos, sr.pos, ja.lager, bet, annahme )

data_mai_baum <- Abstimmungen_Mai %>% 
  select(titel_kurz_d, rechtsform, names(hauptthema), br.pos:nr.pos, sr.pos, ja.lager, bet, annahme )
  
set.seed(1234)
data_split <- initial_split(data_baum, strata = annahme)

data_train <- training(data_split)
data_test <- testing(data_split)


#Prüfen, ob Wahrscheinlichkeiten etwa gleich verteilt sind
prop.table(table(data_train$annahme))
prop.table(table(data_test$annahme))
prop.table(table(data_baum$annahme))


#Parameter für Baum festlegen
tree_specs <- decision_tree(min_n = 10,tree_depth = 5 ) %>% 
             set_engine("rpart") %>% 
              set_mode("classification")

#Model mit allen Variablen im Datenset
model_alles <- tree_specs %>% 
          fit(formula = annahme ~ ., data = data_train ) 


#Model nur mit rechtsform & Ja-Lager
model_br_jalager <- tree_specs %>% 
          fit(formula = annahme ~ rechtsform + ja.lager, data = data_train) 

#Model nur mit Rechtsform & Bundesratsempfehlung
model_br_rechtsform <- tree_specs %>% 
          fit(formula = annahme ~ rechtsform + br.pos, data = data_train)
```


Wir haben für den Baum verschiedene Modelle errechnet, welche die Vorhersagen berechnen:
Model 1: alle Variablen
Model 2: nur Rechtsform und Position des Bundesrates
Model 3: Nur Position des Bundesrates und die Grösse des Ja-Lagers

Model 1 und Model 3 sagen vorher, dass das Filmgesetz abgelehnt wird, während Model 2 für alle Vorlagen eine Annahme vorhersieht. 
```{r Entscheidungsbaum Vorhersagen / Modell} 

#Vorhersagen für Mai gem. obiger Modelle
pred_alles <- predict(model_alles, new_data = data_mai_baum) %>% rename(alles = ".pred_class")
pred_BR_Rechtsform <- predict(model_br_rechtsform, new_data = data_mai_baum) %>%  rename(BR_Rechtsform = ".pred_class")
pred_BR_JaLager <- predict(model_br_jalager, new_data = data_mai_baum) %>%  rename(BR_JaLager = ".pred_class")


#Zusammengefügt in einem Dataframe:
vorhersagen <- cbind(data_mai_baum,pred_alles, pred_BR_Rechtsform, pred_BR_JaLager)  %>% 
  rename(Titel = titel_kurz_d)

select(vorhersagen, Titel, alles, BR_Rechtsform, BR_JaLager)

#Entscheidungsbaum nur mit rpart (Model musste dazu neu erstellt werden da rpart nicht kompatibel mit anderer Library)

#Visualisierung Baum der alle Werte berücksichtigt
model_rpart_alles <- rpart(annahme ~ ., data = data_train, method = 'class',control=rpart.control(minsplit = 10, minbucket = 10, cp=0.01))
rpart.plot(model_rpart_alles, extra = "auto")

#Visualisierung Baum der nur gewählte Faktoren berücksichtigt
model_rpart_reduziert <- rpart(annahme ~ br.pos + sr.pos +nr.pos+ rechtsform + ja.lager + bet, data = data_train, method = 'class',control=rpart.control(minsplit = 10, minbucket = 15, cp=0.001))
rpart.plot(model_rpart_reduziert, extra = "auto")


```
