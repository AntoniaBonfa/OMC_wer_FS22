---
title: "Mini Challenge wer: Vorhersage Abstimmungen Mai"
output: html_notebook
---


Als erstes laden wir alle Pakete, die für dieses Projekt benötigt werden:
```{r Bibliotheken importieren}
library(tidymodels) #Entscheidungsbaum
library(tidyverse) #Datawrangling, Visualisierungen
library(plotly) # Interaktive Visualisierungen
library(formattable) #für Formatierungen -> hier um Prozente schön darzustellen
library(rpart) #Entscheidungsbaum
library(rpart.plot) #Entscheidungsbaum
library(rcompanion)#CramerV

```

Danach wird der Datensatz eingelesen: Swissvotes Datensatz sowie unser eigener Datensatz mit den Vorhersagen der Tamedia & SRG
```{r Datensätze einlesen}
df <- read.csv("https://swissvotes.ch/page/dataset/swissvotes_dataset.csv", header=TRUE, sep=";", na = c("NA", "."))
df_vorhersagen <- read.csv("C:/Users/Antonia/Downloads/Vorhersagen_SRG_Tamedia.csv", header=TRUE, sep=",", na = c("NA", "."))

  
```

Im nächsten Schritt werden die Daten bereinigt, so dass wir einen Datensatz erhalten mit dem wir arbeiten können. 
```{r Data Wrangling}
#Variablen definieren um nachher mehrere Spalten gleichzeitig zu mutieren
parteien <- c(".svp", ".fdp", ".sps", ".cvp", ".gps", ".mitte")


hauptthema <- df %>%
  select(d1e1, d2e1 ,d3e1)


positionen  <- df %>%
  select(ends_with(".pos")|starts_with("p.")|starts_with("pdev")) 

daten <- df %>%
  select(datum, starts_with("dat."))

resultate <- df %>%
  select(ends_with("annahme")| volk | stand)

Thema <- df %>%
  select(d1e3, d2e3, d3e3)


#bereinigten Datensatz erstellen (Variablen benennen, Spalten umbenennen, gewisse NAs droppen, fehlende Werte ergänzen)
df_clean <- df %>%
  mutate(p.cvp = ifelse(p.cvp == "9999", p.mitte, p.cvp))%>% #CVP wurde zu Mitte -> fehlende Daten cvp durch Daten der Mitte ergänzt
  mutate(w.cvp = sum(w.cvp, w.mitte))%>%  #CVP wurde zu Mitte -> fehlende Daten cvp durch Daten der Mitte ergänzt
  mutate(rechtsform = factor(case_when(
    rechtsform == 1 ~ "Obligatorisches Referendum", #OR
    rechtsform == 2 ~ "Fakultatives Referendum", #FR
    rechtsform == 3 ~ "Volksinitiative", #VI
    rechtsform == 4 ~ "Gegenentwurf zu Volksinitiative", #GV
    rechtsform == 5 ~ "Stichfrage")))%>%  #S
  mutate(across(names(positionen), 
           ~ factor(case_when(. == 1 ~ "Befürwortend",
    .== 2 ~"Ablehnend",
    .== 3 ~"Keine",
    .== 4 ~"Leere Abgabe",
    .== 5 ~"Stimmfreigabe",
    .== 8 ~"Vorzug für den Gegenentwurf",
    .== 9 ~"Vorzug für Volksinitiative",
    . == 66 ~"keine",
    . == 9999 ~"Partei ex. nicht",)))) %>%
  mutate(across(names(resultate), 
                ~ factor(case_when(. == 0 ~"abgelehnt", 
                .== 1 ~ "angenommen", 
                .== 3 ~ "Ständemehr nicht nötig", 
                .== 8 ~ "Gegenentwurf angenommen", 
                .== 9 ~ "Volksinitiative angenommen" )))) %>% 
  drop_na(annahme) %>% 
  mutate(volkja.proz = as.numeric(volkja.proz)) %>% 
  select(datum, titel_kurz_d, anzahl, rechtsform, d1e1:br.pos, bv.pos:srnein, unter.quorum, unter_g, unter_u, ends_with(parteien), ja.lager:neutral.summe, volk:ktjaproz) %>%
  mutate(datum = as.Date(datum, "%d.%m.%Y")) %>% 
  rename(p.cvp_mitte = p.cvp, w.cvp_mitte = w.cvp)  %>% 
  select(-c(p.mitte, w.mitte))

pos_parteien <- names(select(df_clean, starts_with("p.")))
```


```{r Datensätze für die Abstimmungen im Mai}
#Abstimmungen vom Mai herausfiltern
Abstimmungen_Mai <- df_clean %>%
  filter(datum > as.Date("01.05.2022", "%d.%m.%Y" )) 


themen <- c(1.62, 2.22, 4.13, 10.32, 12.53)
netflix <- c(12.53, 4.13)
frontex <- c(2.22, 10.32)
organspende <- c(10.11,1.62)


#Abstimmungen mit den selben beiden Themen wie "Lex Netflix" (12.53, 4.13)
wie_netflix <-
  df_clean %>% 
  filter(d1e3 %in% netflix | d2e3 %in% netflix |d3e3 %in% netflix) %>% 
  mutate(across(names(Thema), 
           ~ factor(case_when(. == 1.62 ~ "Grundrechte",
    .== 2.22 ~"Aussenpolitik: EU",
    .== 4.13 ~"Wirtschaft: Strukturpolitik",
    .== 10.32 ~"Sozialpolitik: Flüchtlinge",
    .== 12.53 ~"Medien"))))

#Abstimmungen mit den selben beiden Themen wie Frontex (2.22, 10.32)
wie_frontex <-
  df_clean %>% 
  filter(d1e3 %in% frontex | d2e3 %in% frontex |d3e3 %in% frontex) %>% 
  mutate(across(names(Thema), 
           ~ factor(case_when(. == 1.62 ~ "Grundrechte",
    .== 2.22 ~"Aussenpolitik: EU",
    .== 4.13 ~"Wirtschaft: Strukturpolitik",
    .== 10.32 ~"Sozialpolitik: Flüchtlinge",
    .== 12.53 ~"Medien"))))

#Abstimmungen mit den selben Themen wie die Organspendeinitiative (10.11,1.62)
wie_organspende <-
  df_clean %>% 
  filter(d1e3 %in% organspende | d2e3 %in% organspende |d3e3 %in% organspende) %>% 
  mutate(across(names(Thema), 
           ~ factor(case_when(. == 1.62 ~ "Grundrechte",
    .== 2.22 ~"Aussenpolitik: EU",
    .== 4.13 ~"Wirtschaft: Strukturpolitik",
    .== 10.32 ~"Sozialpolitik: Flüchtlinge",
    .== 12.53 ~"Medien"))))


```

Mittels Kombinatorik wird die Wahrscheinlichkeit gewisser Ereignisse berechnet.
Dabei möchten wir folgende Faktoren untersuchen:
Rechtsform (Volksinitiative, Freiwilliges Referendum, Obligatorisches Referendum, Gegenvorschlag)
Empfehlung des Bundesrats (Befürwortend, ablehnend)
Haltung des Ständerats (befürwortend, ablehnend)
Haltung der grössten Parteien (SVP, SP, FDP, Gründe/Mitte, CVP) (befürwortend, ablehnend, Stimmfreigabe, leer, keine)

```{r Wahrscheinlichkeitsmodell: allgemeine Wahrscheinlichkeiten}
total_vorlagen <- unlist(df_clean %>% count()) 
n_angenommen <-unlist(df_clean %>% filter(annahme == "angenommen") %>% count()) 
n_abgelehnt <- total_vorlagen - n_angenommen
(prob_annahme <- n_angenommen / total_vorlagen)

#Wahrscheinlichkeiten für die Positionen der Parteien (P(C) ∩ P(D) ∩ P(E) ∩ P(F) ∩ P(A)), wenn es sich um ein Fak. Ref handelt:
df_clean %>% 
  #filter(rechtsform == "Fakultatives Referendum")%>% 
  filter_at(vars(pos_parteien), all_vars(.=="Befürwortend"|.== "Ablehnend")) %>% 
  select(pos_parteien, annahme, ) %>%
  count(p.svp, p.fdp, p.sps, p.cvp_mitte, p.gps, annahme) %>% 
  mutate(prob = percent(n/sum(n))) %>% 
  arrange(desc(prob))


#Wahrscheinlichkeiten dass BR ja empfiehlt, wenn Rechtsform Fakultatives Referendum ist (P(B2)):
df_clean %>% 
  filter(rechtsform =="Fakultatives Referendum") %>% 
  select(rechtsform, br.pos) %>% 
  count(rechtsform, br.pos) %>%
  mutate(prob = percent(n/sum(n)))
  
#wahrscheinlichkeit, dass eine Abstimmung angenommen wird bei befürwortender Haltung des BR (P(A2) ∩ P(B2))
brpos <- df_clean %>% 
  filter(br.pos == "Befürwortend") %>% 
  select(br.pos, annahme) %>% 
  count(br.pos, annahme) %>% 
  mutate(prob = percent(n/sum(n)))

prob_brpos <- brpos[2,4]

#Wahrscheinlichkeiten, dass eine Abstimmung angenommen wird, wenn die Rechtsform Fakultatives Referendum ist & der BR befürwortet
FR_BR <- df_clean %>% 
  filter(br.pos == "Befürwortend", rechtsform == "Fakultatives Referendum") %>% 
  select(br.pos, annahme) %>% 
  count(br.pos, annahme) %>% 
  mutate(prob = percent(n/sum(n)))

prob_FR_BR <- FR_BR[2,4]
#Wahrscheinlichkeit, dass ein fakultatives Referendum angenommen wird
prob_FR <- df_clean %>% 
  filter(rechtsform == "Fakultatives Referendum") %>% 
  select(rechtsform, annahme) %>% 
  count(rechtsform, annahme) %>% 
  mutate(prob = percent(n/sum(n)))

#Wahrscheinlichkeit, dass eine Vorlage angenommen wurde wenn Tamedia ein "Ja" vorhergesagt hat:
Tamedia <- df_vorhersagen %>%
  filter(Tamedia == "Annahme") %>% 
  count(Resultat) %>% 
  mutate(prob = percent(n/sum(n)))
prob_Tamedia <- Tamedia[2,3]

#Wahrscheinlichkeit, dass eine Vorlage angenommen wurde wenn SRG ein "Ja" vorhergesagt hat:
SRG <- df_vorhersagen %>%
  filter(SRG == "Annahme") %>% 
  count(Resultat) %>% 
  mutate(prob = percent(n/sum(n)))
prob_SRG <- SRG[2,3]

```


```{r Wahrscheinlichkeit nach Themen}
#Wahrscheinlichkeiten nach Thema
```


```{r Wahrscheinlichkeiten nach Parteiparolen}
#Wahrscheinlichkeit, dass eine Vorlage angenommen wird nach Parteiparolen:
Abstimmungen_Mai %>% 
  select(titel_kurz_d, starts_with("p."))

Filmgesetz_parteien <- df_clean %>% 
  filter(p.svp == "Ablehnend" & p.fdp == "Ablehnend" & p.sps == "Befürwortend" & p.cvp_mitte == "Befürwortend" & p.gps == "Befürwortend" ) %>%     count(annahme) %>% 
  mutate(prob = percent(n/sum(n)) )
prob_Filmgesetz_parteien <- Filmgesetz_parteien[2,3]
         

Organspende_parteien <- df_clean %>% 
  filter(p.svp == "Ablehnend" & p.fdp == "Befürwortend" & p.sps == "Befürwortend" & p.cvp_mitte == "Befürwortend" & p.gps == "Befürwortend" ) %>%   count(annahme) %>% 
  mutate(prob = percent(n/sum(n)))
prob_Organspende_parteien <- Organspende_parteien[2,3]


Frontex_parteien <- df_clean %>% 
  filter(p.svp == "Befürwortend" & p.fdp == "Befürwortend" & p.sps == "Ablehnend" & p.cvp_mitte == "Befürwortend" & p.gps == "Ablehnend" ) %>%    count(annahme) %>% 
  mutate(prob = percent(n/sum(n)))
prob_Frontex_parteien <- Frontex_parteien[2,3]


```

```{r Wahrscheinlichkeitsmodell für jede Vorlage}
Kriterien <- c("Wahrscheinlichkeit nach Rechtsform", 
               "Wahrscheinlichkeit nach Tamedia", 
               "Wahrscheinlichkeit nach SRG", 
               "Wahrscheinlichkeit nach Parteiposition", 
               #"Wahrscheinlichkeit nach Thema", 
               "Wahrscheinlichkeit nach Empfehlung Bundesrat")

Organspende <- data.frame(Kriterien, P = c(prob_FR_BR, 
                                 prob_Tamedia,
                                 prob_SRG,
                                 prob_Organspende_parteien,
                                 #prob_Organspende_thema,
                                 prob_brpos))
(prob_Organspende <- mean(unlist(Organspende["P"])))


Filmgesetz <- data.frame(Kriterien, P = c(prob_FR_BR, 
                                 prob_Tamedia,
                                 prob_SRG,
                                 prob_Filmgesetz_parteien,
                                 #prob_Organspende_thema,
                                 prob_brpos))
(prob_Filmgesetz <- mean(unlist(Filmgesetz["P"])))


Frontex <- data.frame(Kriterien, P = c(prob_FR_BR, 
                                 prob_Tamedia,
                                 prob_SRG,
                                 prob_Frontex_parteien,
                                 #prob_Organspende_thema,
                                 prob_brpos))
(prob_Frontex <- mean(unlist(Frontex["P"])))
```

Anhand unserer Berechnungen wissen wir, wie die Wahrscheinlichkeiten für gewisse Ereignisse sind. Diese müssen wir jetzt mittels Hypothesentest prüfen.
```{r Verteilung der Daten prüfen}
#Histogram zur Prüfung, wie die Daten verteilt sind
ggplot(df_clean, aes(volkja.proz)) +
  geom_histogram(bins = 25)+
  labs(title = "Verteilung Prozentualer ja-Stimmen Anteil",
       x = "Prozentsatz Ja-Stimmen",
       y = "Anzahl Abstimmungen") 

# -> die Daten scheinen in etwa Normalverteilt zu sein. 

#Visualisierung Q-Q Plot -> die Daten sind nicht exakt Normalverteilt (Die Enden sind dazu zu dünn)
qqnorm(df_clean$volkja.proz)
qqline(df_clean$volkja.proz,col="green")

#Überprüfung mittels bootstrapping : wir nehmen 5000 Stichproben von unserem Datensatz und berechnen jeweils den Mittelwert der Stichprobe. 
set.seed(123)
bootstraping <- (replicate(n=5000, 
                       expr = {
                         df_clean %>% 
                           slice_sample(prop = 1, replace = TRUE) %>% 
                           summarize(mean_japroz = mean(volkja.proz)) %>% 
                           pull(mean_japroz)
                        }))


#Verteilung visualisieren -> die Stichproben sind Normalverteilt = Zentraler Grenzwertsatz!
tibble(resample_mean = bootstraping) %>% 
  ggplot(aes(resample_mean)) +
  geom_histogram() +
  labs(title = "Verteilung nach Boostrapping",
       x = "Durchschnitt Ja-Prozentsatz pro Stichprobe",
       y = "Anzahl Stichproben") 

```

```{r Hypothesentests der einzelnen Vorlagen}
#Statistische Kennzahlen von einzelnen Variablen ermitteln (Standardabweichung, Mittelwert)
volk_sd <- sd(df_clean$volkja.proz)
volk_mean <- mean(df_clean$volkja.proz)

#Standardabweichung von der Basiswahrscheinlichkeit
(se_annahme <- (prob_annahme*(1-prob_annahme)**2)/(n_angenommen))
(se_ablehnung <- (prob_annahme*(1-prob_annahme)**2)/(n_abgelehnt))

se_total <- sqrt(se_annahme + se_ablehnung)


#Signifikanzniveau festlegen. Da es keine kritischen Daten sind ist 0.5 für alle Hypothesen ausreichend
alpha = 0.05


#Funktion um P-Wert zu berechnen
p_wert <- function(P_Vorlage) {
  resultat <- pnorm((P_Vorlage-prob_annahme)/se_total, lower.tail = FALSE) #rechtsseitiger Test
  return(ifelse(resultat < alpha, paste("P-Wert:",resultat,"ist kleiner als Signifikanzniveau: Nullhypothese muss verworfen werden."),paste("P-Wert:",resultat,"ist grösser als Signifikanzniveau: Nullhypothese ist erwiesen.") ))
}

p_wert(prob_Filmgesetz)
p_wert(prob_Organspende)
p_wert(prob_Frontex)

```
Zusätzlich zum Hypothesentest für die einzelnen Vorlagen haben wir noch den Einfluss einzelner Variablen mittels Hypothesentest überprüft.
```{r Funktionen für den Hypothesentest}

hypo_fisher <- function(data){
  fisher <- fisher.test(data)
  return (ifelse(fisher$p.value < alpha, paste("P-Wert (", fisher, ") kleiner als Signifikanzniveau: H0 muss verworfen werden."), 
                 paste("P-Wert (", fisher, ") grösser als Signifikanzniveau: H0 ist korrekt.") ))
}

hypo_cramer <- function(data){
cramer <- cramerV(data)
return (case_when(cramer<0.4 ~ paste("CramerV Wert:",cramer, "- keine Abhängigkeit"), 
          cramer<0.7 ~ paste("CramerV Wert:",cramer, "- Mittlere Abhängigkeit"),
          cramer>0.7 ~ paste("CramerV Wert:",cramer, "- Hohe Abhängigkeit")))
}

```

Hypothese 1: Aus der Vorhersage der Tamedia kann nicht auf das Resultat geschlossen werden (H0) / kann das Resultat vorhergesagt werden (Ha)
```{r Hypothese 1: Vorhersage Tamedia} 

#Kreuztabelle Verteilung
(H1 <- table(df_vorhersagen$Tamedia, df_vorhersagen$Resultat))

#Fishers Test durchführen
hypo_fisher(H1)

```
Hypothese 2: Aus der Vorhersage der SRG kann nicht auf das Resultat geschlossen werden (H0) / kann das Resultat vorhergesagt werden (Ha)}
```{r Hypothese 2: Vorhersage SRG} 
#Kreuztabelle Verteilung
(H2 <- table(df_vorhersagen$SRG, df_vorhersagen$Resultat))

#Fishers Test durchführen
hypo_fisher(H2)
```

Hypothese 3: Es gibt keinen signifikanten Zusammenhang zwischen der Empfehlung des Bundesrates und dem Ergebniss (H0) / es gibt einen signifikanten Zusammenhang (Ha)
```{r Hypothese 3: Empfehlung Bundesrat}

#für CramerV darf der Datensatz keine NAs enthalten -> bereinigten Datensatz erstellen: 
df_cramer_3 <- df_clean %>% 
  drop_na(br.pos, volk) %>% 
  mutate(volk = droplevels(volk), br.pos = droplevels(br.pos))

#Kreuztabelle der Verteilungen
(H3 <- table(df_cramer_3$br.pos, df_cramer_3$volk))

#Hypothese überprüfen mittels CramerV & Fishers exact Test (fisher Test zur Sicherheit, da unser Datensatz nicht sehr gross ist)

hypo_fisher(H3)
hypo_cramer(H3)
 
```



Hypothese 4: die Rechtsform hat keinen Einfluss auf das Abstimmungsresultat (H0) / hat einen Einfluss (Ha)
```{r Hypothese 4: Rechtsform}

#für CramerV darf der Datensatz keine NAs enthalten -> bereinigten Datensatz erstellen: 
df_cramer_4 <- df_clean %>% 
  drop_na(rechtsform, volk) %>% 
  mutate(volk = droplevels(volk), rechtsform = droplevels(rechtsform))

#Kreuztabelle der Verteilungen
(H4 <- table(df_cramer_4$rechtsform, df_cramer_4$volk))

#Hypothese überprüfen mittels CramerV & Fishers exact Test (fisher Test zur Sicherheit, da unser Datensatz nicht sehr gross ist)
hypo_fisher(H4)
hypo_cramer(H4)
 
```


Als zusätzlichen Schritt haben wir versucht, einen Entscheidungsbaum zu erstellen, der das Resultat ebenfalls vorhersagt. 
```{r Entscheidungsbaum} 

#reduzierter Datensatz für Baum (Entfernung Resultatvariablen wie Volk, Kanton, Resultate pro Kanton etc):
data_baum <- df_clean %>% select(rechtsform, names(hauptthema), br.pos:nr.pos, sr.pos, ja.lager, bet, annahme )

data_mai_baum <- Abstimmungen_Mai %>% 
  select(titel_kurz_d, rechtsform, names(hauptthema), br.pos:nr.pos, sr.pos, ja.lager, bet, annahme )
  
organspende <- data_mai_baum %>%  filter(titel_kurz_d =="Widerspruchsregelung bei der Organspende")
Frontex <- data_mai_baum %>%  filter(titel_kurz_d == "Beteiligung an der europäischen Grenz- und Küstenwache Frontex") 
filmgesetz <- data_mai_baum %>%  filter(titel_kurz_d == "Änderung des Filmgesetzes") 

set.seed(1234)
data_split <- initial_split(data_baum, strata = annahme)

data_train <- training(data_split)
data_test <- testing(data_split)


#Prüfen, ob Wahrscheinlichkeiten etwa gleich verteilt sind
prop.table(table(data_train$annahme))
prop.table(table(data_test$annahme))
prop.table(table(data_baum$annahme))


#Parameter für Baum festlegen
tree_specs <- decision_tree(min_n = 10,tree_depth = 5 ) %>% 
             set_engine("rpart") %>% 
              set_mode("classification")

#Model mit allen Variablen im Datenset
model_alles <- tree_specs %>% 
          fit(formula = annahme ~ ., data = data_train ) 


#Model nur mit rechtsform & Ja-Lager
model_br_jalager <- tree_specs %>% 
          fit(formula = annahme ~ rechtsform + ja.lager, data = data_train) 

#Model nur mit Rechtsform & Bundesratsempfehlung
model_br_rechtsform <- tree_specs %>% 
          fit(formula = annahme ~ rechtsform + br.pos, data = data_train) 

#Vorhersagen für Mai gem. obiger Modelle
pred_alles <- predict(model_alles, new_data = data_mai_baum) %>% rename(alles = ".pred_class")
pred_BR_Rechtsform <- predict(model_br_rechtsform, new_data = data_mai_baum) %>%  rename(BR_Rechtsform = ".pred_class")
pred_BR_JaLager <- predict(model_br_jalager, new_data = data_mai_baum) %>%  rename(BR_JaLager = ".pred_class")

#Zusammengefügt in einem Dataframe:
(vorhersagen <- cbind(data_mai_baum,pred_alles, pred_BR_Rechtsform, pred_BR_JaLager)  %>% 
  select(-c(nr.pos, sr.pos, bv.pos)) %>% 
  rename(Titel = titel_kurz_d))


#Entscheidungsbaum nur mit rpart (Model musste dazu neu erstellt werden da rpart nicht kompatibel mit anderer Library)

#Visualisierung Baum der alle Werte berücksichtigt
model_rpart_alles <- rpart(annahme ~ ., data = data_train, method = 'class',control=rpart.control(minsplit = 10, minbucket = 10, cp=0.01))
rpart.plot(model_rpart_alles, extra = "auto")

#Visualisierung Baum der nur gewählte Faktoren berücksichtigt
model_rpart_reduziert <- rpart(annahme ~ br.pos + sr.pos +nr.pos+ rechtsform + ja.lager + bet, data = data_train, method = 'class',control=rpart.control(minsplit = 10, minbucket = 15, cp=0.001))
rpart.plot(model_rpart_reduziert, extra = "auto")


```







1